---
title: "Publications"
description: |
  My research publications
date: 2023-10-01
image: featured.jpg
image-alt: |
  Blue abstract design representing machine learning and AI concepts
toc: true
categories:
  - machine learning
  - deep learning
  - time series forecasting
  - generative models
  - bayesian optimization
---

## Publications

My research focuses on developing innovative machine learning methods with a particular emphasis on **time series forecasting**, **generative models**, and **Bayesian optimization**. I work on creating efficient, scalable solutions for complex real-world problems while advancing the theoretical foundations of machine learning.

### Featured Research

- **Time Series Forecasting and Generalization**: My work on the Woods benchmark provides standardized evaluation of models under distribution shifts, a critical challenge in real-world applications.

- **Generative Flow Networks (GFNs)**: I contribute to the development of GFNs for various applications, including improved regularization techniques for deep neural networks.

- **Bayesian Optimization**: My research explores efficient hyperparameter tuning for neural networks using approximate Bayesian methods.

### Journal Articles and Conference Papers

- JC Gagnon-Audet, K Ahuja, MJ Darvishi-Bayazi, P Mousavi, G Dumas, **N Hass**, et al. (2022). "Woods: Benchmarks for Out-of-Distribution Generalization in Time Series." _arXiv preprint arXiv:2203.09978_. _(Cited by 47)_

- D Liu, M Jain, BFP Dossou, Q Shen, S Lahlou, A Goyal, **N Hass**, et al. (2023). "GFlowOut: Dropout with Generative Flow Networks." _International Conference on Machine Learning (ICML)_, 21715-21729. _(Cited by 24)_

- **N Hass**, I Rish (2021). "Approximate Bayesian Optimisation for Neural Networks." _arXiv preprint arXiv:2108.12461_. _(Cited by 2)_

### Current Research Focus

I am currently exploring the intersection of generative models and reinforcement learning, with applications in sequential decision making and time series analysis. I am also interested in developing scalable methods for uncertainty quantification in deep learning models.
